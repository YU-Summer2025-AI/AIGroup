{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install scikit-learn\n",
    "%pip install pgvector\n",
    "%pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import xgboost as xgb\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, fbeta_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vector_fast(vec_str):\n",
    "            if isinstance(vec_str, str):\n",
    "                try:\n",
    "                    # Safely parse the string using the optimized json library\n",
    "                    return np.array(json.loads(vec_str))[:50]\n",
    "                except json.JSONDecodeError:\n",
    "                    # Handle cases where the string is not valid JSON\n",
    "                    return None\n",
    "            elif hasattr(vec_str, '__iter__'): # Check if it's already a list/array\n",
    "                return np.array(vec_str)[:50]\n",
    "            return None # Handle other potential null/malformed data\n",
    "\n",
    "\n",
    "\n",
    "engine = create_engine(\"postgresql+psycopg2://admin:admin@localhost:5432/SYAS\")\n",
    "sql_query = text(\"SELECT * FROM matches_values\")\n",
    "processed_chunks = []\n",
    "with engine.connect().execution_options(stream_results=True) as conn:\n",
    "    #df = pd.read_sql(sql_query, conn)\n",
    "    df_iterator = pd.read_sql(sql_query, conn, chunksize=10000)\n",
    "    for i, chunk_df in enumerate(df_iterator):\n",
    "        print(f\"Processing chunk {i+1}...\")\n",
    "        for col in chunk_df:\n",
    "            if 'embedding' in col:\n",
    "                chunk_df[col] = chunk_df[col].apply(parse_vector_fast)\n",
    "        processed_chunks.append(chunk_df)\n",
    "\n",
    "df = pd.concat(processed_chunks, ignore_index=True)\n",
    "processed_chunks = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_add = []\n",
    "cols_to_remove = []\n",
    "for col in df.columns.copy():\n",
    "    if df[col].dtype == 'object' and 'embedding' not in col:\n",
    "        df[col] = df[col].str.replace(' ', '')\n",
    "        df[col] = df[col].replace('', np.nan) \n",
    "        should_drop_first = not col.endswith('list')\n",
    "        dummy_columns = df[col].str.get_dummies(sep=';').astype(int).add_prefix(col + '_')\n",
    "        if should_drop_first:\n",
    "            # Remove extra column \n",
    "            dummy_columns = dummy_columns.iloc[:, 1:]\n",
    "        print(col, should_drop_first)\n",
    "        cols_to_remove.append(col)\n",
    "        cols_to_add.append(dummy_columns)\n",
    "    elif 'embedding' in col:\n",
    "        print('embedding', col)\n",
    "        first_valid_vector = next((v for v in df[col] if v is not None), None)\n",
    "        vec_len = len(first_valid_vector)\n",
    "        nan_placeholder = [np.nan] * vec_len\n",
    "        data_for_df = [v if v is not None else nan_placeholder for v in df[col].tolist()]\n",
    "        vector_df = pd.DataFrame(\n",
    "            data_for_df,\n",
    "            index=df.index,\n",
    "            dtype=np.float32  \n",
    "        )\n",
    "        vector_df.columns = [f'{col}_{i}' for i in range(vector_df.shape[1])]\n",
    "        cols_to_remove.append(col)\n",
    "        cols_to_add.append(vector_df)\n",
    "    \n",
    "df = pd.concat([df.drop(cols_to_remove, axis=1)] + cols_to_add, axis=1)\n",
    "cols_to_add = None\n",
    "cols_to_remove = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pd.read_csv('match_distances.csv')\n",
    "df = df.merge(distances, left_on='match_id', right_on='id').drop(['id'], axis=1)\n",
    "# df = df.drop(['match_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('match_status_Declined', axis=1)\n",
    "y =  1 - df['match_status_Declined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['match_id'].to_csv('test_match_ids.csv', index=False)\n",
    "x_test = x_test.drop(['match_id'], axis=1)\n",
    "x_train = x_train.drop(['match_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='logloss',     \n",
    "    use_label_encoder=False,    \n",
    "    n_estimators=1000,\n",
    "    subsample = .8,\n",
    "    learning_rate=0.05,\n",
    "    scale_pos_weight=40,\n",
    "    colsample_bytree=0.7,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_proba = model.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "f2 = fbeta_score(y_train, y_train_pred, beta=2)\n",
    "print(f\"F2 Score Train: {f2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "print(f\"F2 Score Test: {f2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Declined', 'Both Approve'],\n",
    "            yticklabels=['Declined', 'Both Approve'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"top_xgb_model_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_threshold = 0.55\n",
    "y_pred_custom = (y_pred_proba > custom_threshold).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred_custom)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Declined', 'Both Approve'],\n",
    "            yticklabels=['Declined', 'Both Approve'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix (55% Threshold)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({\n",
    "    'feature': model.feature_names_in_,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "num_features = len(model.feature_names_in_)\n",
    "plot_height = max(6, num_features / 2.5)\n",
    "\n",
    "plt.figure(figsize=(10, plot_height))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for index, row in feature_importances.iterrows():\n",
    "    if \"embedding\" in row['feature']:\n",
    "        total += row['importance']\n",
    "print(total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
