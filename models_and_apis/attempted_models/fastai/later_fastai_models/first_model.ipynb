{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "from fastai.tabular.all import *\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    selected_device = torch.device(\"mps\")\n",
    "    print(\"Using Apple Silicon\")\n",
    "else:\n",
    "    selected_device = torch.device(\"cpu\")\n",
    "    print(\"MPS not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql+psycopg2://admin:admin@localhost:5432/SYAS\")\n",
    "sql_query = text(\"SELECT * FROM matches_values\")\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(sql_query, conn)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names = df.select_dtypes(include='number').columns.to_list()\n",
    "cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'match_status'\n",
    "cat_names = [col for col in df.columns if col not in cont_names + [dep_var]]\n",
    "cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [Categorify, FillMissing, Normalize]\n",
    "dls = TabularDataLoaders.from_df(\n",
    "    df,\n",
    "    path='.',\n",
    "    procs=procs,\n",
    "    cat_names=cat_names,\n",
    "    cont_names=cont_names,\n",
    "    y_names=dep_var,\n",
    "    valid_pct=0.2,\n",
    "    seed=42,\n",
    "    device=selected_device,\n",
    "    y_block=CategoryBlock\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = tabular_learner(dls, metrics=F1Score(pos_label=0), loss_func=FocalLossFlat())\n",
    "# learn.fit_one_cycle(10, cbs= [\n",
    "#     EarlyStoppingCallback(monitor='valid_loss', patience=2),\n",
    "#     SaveModelCallback(monitor='valid_loss')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal loss failed, so I'll switch to using custom class weights in the loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = dls.train_ds.items['match_status']\n",
    "counts = Counter(train_y)\n",
    "num_classes = len(counts)\n",
    "total_samples = sum(counts.values())\n",
    "weights = []\n",
    "for i in range(num_classes):\n",
    "    weight = total_samples / (num_classes * counts[i])\n",
    "    weights.append(weight)\n",
    "class_weights = torch.tensor(weights, dtype=torch.float32).to(dls.device)\n",
    "# manual_weights = torch.tensor([25.0, 0.54], dtype=torch.float32).to(dls.device)\n",
    "weighted_loss_func = nn.CrossEntropyLoss(weight=class_weights)\n",
    "def squeezed_loss_func(preds, targs, **kwargs):\n",
    "    # Target tensor has too many dimensions\n",
    "    return weighted_loss_func(preds, targs.squeeze(), **kwargs)\n",
    "print(f\"Calculated Weights (for class 0, then 1): {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=F1Score(pos_label=0), loss_func=squeezed_loss_func)\n",
    "suggestions = learn.lr_find(suggest_funcs=(valley, slide))\n",
    "\n",
    "suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, lr_max=0.0004, cbs= [\n",
    "    EarlyStoppingCallback(monitor='f1_score', patience=2),\n",
    "    SaveModelCallback(monitor='f1_score')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs = learn.get_preds(ds_idx=1)\n",
    "predicted_classes = preds.argmax(dim=1)\n",
    "cm = confusion_matrix(targs, predicted_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dls.vocab)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"changed_weights_improved_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, lr_max=0.001445, cbs= [\n",
    "    EarlyStoppingCallback(monitor='f1_score', patience=2),\n",
    "    SaveModelCallback(monitor='f1_score')\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
